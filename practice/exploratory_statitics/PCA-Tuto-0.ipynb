{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice on PCA\n",
    "\n",
    "This practice is to get you started with the Principal Component Analysis\n",
    "You will:\n",
    "\n",
    "    - Load data from the cloud (CMIP6 historical run)\n",
    "    - Format data for the PCA\n",
    "    - Run PCA analysis\n",
    "    - Plot results (time series and map of patterns)\n",
    "\n",
    "Statistically, the goal is to reduce the dimensionality of the problem from $N$ grid points (this could be a collection of maps or vertical profiles) down to a few principal components.\n",
    "\n",
    "In class, we've seen that for a (time) series (along the dimension $t$) of maps, the PCA will lead to the decomposition:\n",
    "\\begin{eqnarray}\n",
    "\t\\mathbf{v}(t) &=& \\sum_{j=1}^{Nc} \\mathbf{P}(t,j) \\mathbf{y}(j)\n",
    "\\end{eqnarray}\n",
    "where $\\mathbf{P}\\in \\mathbb{R}^{Nt\\times Nc}$ and $\\mathbf{y}\\in \\mathbb{R}^{Nc\\times Np}$ with $Nc\\leq N$. \n",
    "The first rows of $\\mathbf{P}$ contain profiles maximizing the temporal variance throughout the collection of profiles.\n",
    "\n",
    "Doc:\n",
    "\n",
    "- https://dask-ml.readthedocs.io/en/latest/modules/generated/dask_ml.decomposition.PCA.html\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If you run this notebook at colab.research.google.com, you need to install packages with the following command*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade dask distributed dask-ml xarray zarr gcsfs cftime nc-time-axis intake intake-xarray scikit-learn matplotlib==3.0.2 seaborn\n",
    "!apt-get -qq install python-cartopy python3-cartopy\n",
    "!curl https://raw.githubusercontent.com/obidam/ds2-2020/ds2-2021/practice/exploratory_statitics/tuto_tools.py --output tuto_tools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import gcsfs\n",
    "gcs = gcsfs.GCSFileSystem(token='anon') # this only needs to be created once\n",
    "\n",
    "from dask_kubernetes import KubeCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "from tuto_tools import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (15,10)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep using an existing dask cluster one:\n",
    "client = Client('tcp://10.32.5.177:33497') # Update with appropriate value of the current dask cluster scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or start a new one:\n",
    "cluster = KubeCluster(n_workers=20)\n",
    "scheduler_address = cluster.scheduler_address \n",
    "client = Client(scheduler_address) # Instantiate the dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whatever your choice, you should have a client set-up:\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data to analyse\n",
    "\n",
    "We gonna work with Atmospheric Sea Surface Pressure fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look into CMIP6 data catalog:\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the catalog to get the zstore entry point of a given dataset:\n",
    "\n",
    "# Atmospheric Surface Temperature:\n",
    "# df_ta = df.query(\"activity_id=='CMIP' & table_id == 'Amon' & variable_id == 'tas' & experiment_id == 'historical' & source_id == 'IPSL-CM6A-LR' & member_id == 'r1i1p1f1'\")\n",
    "\n",
    "# Sea Level Pressure:\n",
    "df_ta = df.query(\"activity_id=='CMIP' & table_id == 'Amon' & variable_id == 'psl' & experiment_id == 'historical' & source_id == 'IPSL-CM6A-LR' & member_id == 'r1i1p1f1'\")\n",
    "\n",
    "#\n",
    "df_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path to a specific zarr store (the first one from the dataframe above)\n",
    "zstore = df_ta.zstore.values[-1]\n",
    "\n",
    "# create a mutable-mapping-style interface to the store\n",
    "mapper = gcs.get_mapper(zstore)\n",
    "\n",
    "# open it using xarray and zarr\n",
    "ds = xr.open_zarr(mapper, consolidated=True)\n",
    "print(ds.nbytes/1e9,\"Gb\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We may also need the surface of cells:\n",
    "df_area = df.query(\"variable_id == 'areacella' & source_id == 'IPSL-CM6A-LR'\")\n",
    "ds_area = xr.open_zarr(gcs.get_mapper(df_area.zstore.values[0]), consolidated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/ Create a new variable 'da' with the xarray.DataArray of interest in 'ds':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2/ Get a quick look at the data (draw a map with one time slice):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3/ Create a working copy of the data array and select only the North Atlantic region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = da.copy()\n",
    "v = v.sel(lon=slice(360-100,360)).sel(lat=slice(0,90)) # North Atlantic\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PCA lib:\n",
    "from dask_ml.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4/ Re-format your array to fit the PCA\n",
    "\n",
    "To run the PCA, you need a ```[n_samples, n_features]``` array.  \n",
    "You can use the xarray [```stack```](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.stack.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/ Run the PCA with the ```fit``` method\n",
    "\n",
    "[Click here for help on PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Instantiate the PCA:\n",
    "reducer = PCA(n_components=20, random_state=6789)\n",
    "\n",
    "# Compute eigen vectors of the covariance matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of components retained (the new dimensions of the reduced array)\n",
    "Nc = reducer.n_components_\n",
    "\n",
    "# Eigen vectors (maps defining the the new/reduced space):\n",
    "P = reducer.components_ # [Nc , n_features], the P matrix\n",
    "print(P.shape)\n",
    "\n",
    "# Amount of variance explained by each eigen vectors (with 0 to 1 values):\n",
    "eVar = reducer.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6/ Compute eigen values (ie the time series with intensity of each eigen vectors in this dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7/ Fill in new xarray DataArrays with the PCA results\n",
    "\n",
    "The syntax to create a new xarray.DataArray is:\n",
    "\n",
    "    xr.DataArray( <ARRAY_VALUES>, dims=<LIST_OF_DIMENSION_NAMES>, coords=<DICT_OF_DIMENSIONS>, name=<NAME_OF_THE_DataArray>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = \n",
    "y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8/ Plot the annual mean time series of each PCA components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sel(Nc=range(0,3)).groupby('time.year').mean(dim='time').plot(hue='Nc');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9/ Plot the map of each PCA components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.sel(Nc=slice(0,9)).plot(x='lon', y='lat', col='Nc', col_wrap=5, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10/ Plot the variance explained by each component (```eVar```):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
